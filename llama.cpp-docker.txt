# docker 下面运行的提示（for Sky）
1. docker pull rocm/pytorch:rocm6.0_ubuntu22.04_py3.9_pytorch_2.0.1
2. 解压并使用 llama.cpp_with_models.zip 文件  （source code 位于：https://github.com/colorpepper/llama.cpp/tree/master）
3. 步骤参考 output results_W7800.txt 文件中的内容（涉及benchmark 和 实际输入prompt 给出output text 应用）
